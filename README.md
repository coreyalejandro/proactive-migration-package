# PROACTIVE AI Constitution Research Toolkit

**A comprehensive framework for Constitutional AI safety research, from ideation to arXiv publication.**

[![Status](https://img.shields.io/badge/Status-Active%20Development-yellow)]()
[![Version](https://img.shields.io/badge/Version-1.0.0-blue)]()
[![License](https://img.shields.io/badge/License-Research-green)]()

---

## Overview

The PROACTIVE AI Constitution is a systematic framework for AI safety research that operationalizes a core thesis:

> **Reliability failures are safety failures.** When an AI system makes confident claims about reality that are false, and users must rely on those claims to act, the resulting harm is operationally indistinguishable from maliceâ€”regardless of intent.

This toolkit provides everything needed to go from research idea to arXiv-ready publication, aligned with Anthropic's Responsible Scaling Policy and contemporary AI safety research standards.

---

## Core Thesis

```
"Epistemic reliability is a safety requirement, not a quality feature."
```

The framework addresses this through three integrated mechanisms:

1. **Cognitive Operating Layer (COL)**: A boundary layer that compiles user intent, constraints, and risk posture into a traceable representation before any action is taken

2. **PROACTIVE Constitution**: Nine enforceable behavioral constraints implemented as gates that cannot be bypassed

3. **MBSE Bridge**: A trace chain (Requirement â†’ Control â†’ Test â†’ Evidence â†’ Decision) that makes requirements executable and decisions auditable

---

## Repository Structure

```
PROACTIVE-AI-CONSTITUTION-TOOLKIT/
â”‚
â”œâ”€â”€ README.md                          â† You are here
â”‚
â”œâ”€â”€ 01_FOUNDATIONS/                    âœ“ EXISTS (6 documents)
â”‚   â”œâ”€â”€ PROACTIVE_AI_CONSTITUTION.md   â† Master organizing principle
â”‚   â”œâ”€â”€ THEORY_OF_CHANGE.md            â† Why + What (threat model, F1-F5)
â”‚   â”œâ”€â”€ THEORY_OF_ACTION.md            â† How + Verify (causal model)
â”‚   â”œâ”€â”€ PRD_COL_PROACTIVE_MBSE.md      â† Implementation specification
â”‚   â”œâ”€â”€ FRAMEWORK_GUIDE.md             â† Meta-organization document
â”‚   â””â”€â”€ RESEARCH_STARTER_KIT.md        â† Reading order + research questions
â”‚
â”œâ”€â”€ 02_PROGRAM_GOVERNANCE/             âš ï¸ TO CREATE (Stage 0)
â”‚   â”œâ”€â”€ RESEARCH_PROGRAM_CHARTER.md
â”‚   â”œâ”€â”€ ASSUMPTIONS_REGISTER.md
â”‚   â””â”€â”€ SAFETY_CASE_SKELETON.md
â”‚
â”œâ”€â”€ 03_LITERATURE_POSITIONING/         âš ï¸ TO CREATE (Stage 1)
â”‚   â”œâ”€â”€ LITERATURE_MAP.md
â”‚   â”œâ”€â”€ COMPARATIVE_FRAMEWORK_MATRIX.md
â”‚   â””â”€â”€ OPERATIONAL_DEFINITIONS_GLOSSARY.md
â”‚
â”œâ”€â”€ 04_FORMAL_SPECIFICATION/           âš ï¸ TO CREATE (Stage 2)
â”‚   â”œâ”€â”€ FORMAL_SPEC_PACK.md
â”‚   â”œâ”€â”€ TRACEABILITY_ONTOLOGY.md
â”‚   â”œâ”€â”€ BENCHMARK_CLAIM_SET.md
â”‚   â””â”€â”€ ETHICS_ACCESSIBILITY_ADDENDUM.md
â”‚
â”œâ”€â”€ 05_EVALUATION_DESIGN/              âš ï¸ TO CREATE (Stage 4) â€” PRIORITY
â”‚   â”œâ”€â”€ EVALUATION_PLAN_PREREGISTERED.md
â”‚   â”œâ”€â”€ BASELINE_SUITE_DEFINITION.md
â”‚   â”œâ”€â”€ BENCHMARK_TASK_SETS.md
â”‚   â”œâ”€â”€ METRICS_SPECIFICATION.md
â”‚   â”œâ”€â”€ RED_TEAM_PROTOCOL.md
â”‚   â””â”€â”€ HUMAN_FACTORS_PROTOCOL.md
â”‚
â”œâ”€â”€ 06_DATA_QUALITY/                   âš ï¸ TO CREATE (Stage 5)
â”‚   â”œâ”€â”€ DATASET_CARDS.md
â”‚   â”œâ”€â”€ ANNOTATION_GUIDELINES.md
â”‚   â”œâ”€â”€ INTER_RATER_RELIABILITY_TEMPLATE.md
â”‚   â””â”€â”€ REPRODUCIBILITY_CHECKLIST.md
â”‚
â”œâ”€â”€ 07_ANALYSIS_TEMPLATES/             âš ï¸ TO CREATE (Stage 6)
â”‚   â”œâ”€â”€ PRIMARY_RESULTS_TEMPLATE.md
â”‚   â”œâ”€â”€ ABLATION_STUDY_TEMPLATE.md
â”‚   â”œâ”€â”€ FAILURE_MODE_CATALOG_TEMPLATE.md
â”‚   â””â”€â”€ LIMITATIONS_THREATS_TEMPLATE.md
â”‚
â”œâ”€â”€ 08_PUBLICATION/                    âš ï¸ TO CREATE (Stage 7)
â”‚   â”œâ”€â”€ PAPER_TEMPLATE_ARXIV.md
â”‚   â”œâ”€â”€ SUPPLEMENTARY_MATERIALS_TEMPLATE.md
â”‚   â”œâ”€â”€ OPEN_SCIENCE_BUNDLE_SPEC.md
â”‚   â””â”€â”€ RESPONSIBLE_DISCLOSURE_TEMPLATE.md
â”‚
â””â”€â”€ 09_SAFETY_CASE/                    âš ï¸ TO CREATE (Synthesis)
    â””â”€â”€ SAFETY_CASE_FULL.md
```

---

## Document Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PROACTIVE AI CONSTITUTION                                 â”‚
â”‚                     (Master Organizing Principle)                                â”‚
â”‚                                                                                  â”‚
â”‚   "Epistemic reliability is a safety requirement, not a quality feature."        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                           â”‚                           â”‚
          â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  THEORY OF CHANGE   â”‚   â”‚  THEORY OF ACTION   â”‚   â”‚       PROACTIVE COL         â”‚
â”‚   (WHY + WHAT)      â”‚   â”‚   (HOW + VERIFY)    â”‚   â”‚    (PRD IMPLEMENTATION)     â”‚
â”‚                     â”‚   â”‚                     â”‚   â”‚                             â”‚
â”‚ â€¢ Core Claims       â”‚   â”‚ â€¢ Causal Model      â”‚   â”‚ â€¢ Cognitive Operating Layer â”‚
â”‚ â€¢ Threat Model      â”‚   â”‚ â€¢ Falsifiability    â”‚   â”‚ â€¢ PROACTIVE Mnemonic (9)    â”‚
â”‚ â€¢ F1-F5 Taxonomy    â”‚   â”‚ â€¢ Ablation Design   â”‚   â”‚ â€¢ Six Invariants (I1-I6)    â”‚
â”‚ â€¢ Validity Portfolioâ”‚   â”‚ â€¢ Baseline Rationaleâ”‚   â”‚ â€¢ MBSE Bridge (Trace Chain) â”‚
â”‚ â€¢ Governance        â”‚   â”‚ â€¢ Applicability     â”‚   â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Foundation Documents (Exist)

| Document | Answers | Purpose |
|----------|---------|---------|
| **PROACTIVE_AI_CONSTITUTION.md** | "What must never be violated?" | Enforceable behavioral constraints, Six Invariants (I1-I6), PROACTIVE mnemonic |
| **THEORY_OF_CHANGE.md** | "Why does this matter?" | Threat model, F1-F5 failure taxonomy, validity portfolio, governance |
| **THEORY_OF_ACTION.md** | "How do we know it works?" | Causal DAG, falsifiability conditions, ablation design, baselines |
| **PRD_COL_PROACTIVE_MBSE.md** | "How exactly is it built?" | COL architecture, trace chain, Constitutional Validator, evaluation protocols |
| **FRAMEWORK_GUIDE.md** | "How do docs relate?" | Meta-organization, terminology standardization, Anthropic alignment matrix |
| **RESEARCH_STARTER_KIT.md** | "Where do I start?" | Reading order by audience, research questions, evaluation artifacts |

---

## Idea-to-arXiv Pipeline

### Stage 0: Program Governance
Establish research contract, safety governance, and scope.

### Stage 1: Literature Positioning
Anchor framework in existing research, identify gaps.

### Stage 2: Formal Specification
Convert concepts to testable specifications with clear interfaces.

### Stage 3: MVP Implementation
Build minimal system for reproducible evaluation (research-grade).

### Stage 4: Evaluation Design â­ PRIORITY
Create modern, credible evaluations aligned with Anthropic standards.

### Stage 5: Data Collection
Ensure evidence is publication-grade and audit-ready.

### Stage 6: Analysis & Interpretation
Turn results into defensible claims with calibrated uncertainty.

### Stage 7: Publication Package
Structure work for peer review and community scrutiny.

---

## Priority Documents to Create

| Priority | Document | Why Critical for arXiv |
|----------|----------|------------------------|
| **P0** | EVALUATION_PLAN_PREREGISTERED.md | Reviewers expect pre-registration or equivalent rigor |
| **P0** | BENCHMARK_TASK_SETS.md | No empirical claim without benchmarks |
| **P0** | METRICS_SPECIFICATION.md | Operationalizes what "success" means |
| **P1** | PAPER_TEMPLATE_ARXIV.md | Structures the actual submission |
| **P1** | BASELINE_SUITE_DEFINITION.md | "Compared to what?" is the first reviewer question |
| **P1** | SAFETY_CASE_FULL.md | Anthropic-style claimâ†’argumentâ†’evidence synthesis |
| **P2** | LITERATURE_MAP.md | Positions contribution in existing work |
| **P2** | RED_TEAM_PROTOCOL.md | Robustness claims require adversarial testing |
| **P2** | REPRODUCIBILITY_CHECKLIST.md | arXiv increasingly expects this |

---

## Recommended Creation Timeline

```
Week 1: P0 Documents (Evaluation Core)
â”œâ”€â”€ EVALUATION_PLAN_PREREGISTERED.md
â”œâ”€â”€ BENCHMARK_TASK_SETS.md
â””â”€â”€ METRICS_SPECIFICATION.md

Week 2: P1 Documents (Publication Structure)
â”œâ”€â”€ PAPER_TEMPLATE_ARXIV.md
â”œâ”€â”€ BASELINE_SUITE_DEFINITION.md
â””â”€â”€ SAFETY_CASE_FULL.md

Week 3: P2 Documents (Rigor & Positioning)
â”œâ”€â”€ LITERATURE_MAP.md
â”œâ”€â”€ RED_TEAM_PROTOCOL.md
â””â”€â”€ REPRODUCIBILITY_CHECKLIST.md

Week 4: P3 Documents (Technical Depth)
â”œâ”€â”€ FORMAL_SPEC_PACK.md
â”œâ”€â”€ ABLATION_STUDY_TEMPLATE.md
â””â”€â”€ FAILURE_MODE_CATALOG_TEMPLATE.md
```

---

## Key Framework Components

### PROACTIVE Mnemonic (9 Principles)

| Letter | Principle | Enforcement |
|--------|-----------|-------------|
| **P** | Privacy-First | Collect minimum data; default local-only |
| **R** | Reality-Bound | Distinguish facts/inference/speculation |
| **O** | Observability | Emit structured logs; forensics-ready |
| **A** | Accessibility | Minimize cognitive load; support stepwise |
| **C** | Constitutional Constraints | Enforce rules as gates; never bypass |
| **T** | Truth or Bounded Unknown | Never misrepresent capability; mark uncertainty |
| **I** | Intent Integrity | Preserve user intent; refuse ambiguous execution |
| **V** | Verification Before Action | Perform checks before claiming success |
| **E** | Error Ownership | Own and repair mistakes instead of hiding |

### Six Invariants (I1-I6)

| Invariant | Name | Rule |
|-----------|------|------|
| **I1** | Evidence-First | Every claim must carry epistemic tag + evidence |
| **I2** | No Phantom Work | Cannot claim work unless artifact exists |
| **I3** | Confidence-Verification | High confidence only with verification artifacts |
| **I4** | Traceability Mandatory | REQâ†’CTRLâ†’TESTâ†’EVIDâ†’DECISION linked |
| **I5** | Safety Over Fluency | Bounded statements over fluent narrative |
| **I6** | Fail Closed | Stop and surface failure; do not work around |

### F1-F5 Failure Taxonomy

| Class | Name | Description |
|-------|------|-------------|
| **F1** | Confident False Claims | High confidence on objectively false statements |
| **F2** | Phantom Completion | Claiming work done when no artifact exists |
| **F3** | Persistence Under Correction | Maintaining false claims after correction |
| **F4** | Harm-Risk Coupling | False claims in high-consequence domains |
| **F5** | Cross-Episode Recurrence | Same failure patterns across sessions |

---

## Reading Order by Audience

### For Safety Researchers
1. THEORY_OF_CHANGE.md (threat model, F1-F5 taxonomy)
2. PROACTIVE_AI_CONSTITUTION.md (invariants, enforcement)
3. THEORY_OF_ACTION.md (falsifiability, ablation)
4. PRD_COL_PROACTIVE_MBSE.md (evaluation protocols)

### For Systems Engineers
1. PRD_COL_PROACTIVE_MBSE.md (architecture, trace chain)
2. PROACTIVE_AI_CONSTITUTION.md (gate implementation)
3. THEORY_OF_CHANGE.md (MBSE bridge, validity)
4. THEORY_OF_ACTION.md (causal model)

### For Evaluation Designers
1. THEORY_OF_ACTION.md (entire document)
2. PRD Â§7 (evaluation protocols)
3. THEORY_OF_CHANGE.md Â§5 (F1-F5), Â§8 (governance)
4. PROACTIVE_AI_CONSTITUTION.md Â§4 (invariant specifications)

---

## Anthropic Alignment Coverage

| Dimension | Coverage |
|-----------|----------|
| Evaluating Alignment | â—â—â— High |
| AI Control | â—â—â— High |
| Honesty | â—â—â— High |
| Behavioral Monitoring | â—â—â— High |
| Adversarial Robustness | â—â—â— High |
| CoT Faithfulness | â—â—â—‹ Medium-High |
| Scalable Oversight | â—â—â—‹ Medium |
| Activation Monitoring | â—â—‹â—‹ Low |
| Multi-Agent | â—â—‹â—‹ Low |

---

## Key Research Questions

1. **Effectiveness**: Does the framework reduce F1-F5 failure rates compared to baselines?
2. **Mechanism Attribution**: Which components (COL, IT-Loop, Validator, Trace) contribute most?
3. **Robustness**: Do invariants hold under adversarial pressure and distribution shift?
4. **Human Factors**: Can users understand intent receipts and detect errors?
5. **Scalability**: Does trace fidelity degrade at scale?
6. **Generalization**: Does the framework transfer across domains and architectures?

---

## Adapter Modules

The PROACTIVE framework includes adapter modules that integrate with external tools to validate specific principles and invariants.

| Adapter | Purpose | Validates | Status |
|---------|---------|-----------|--------|
| [01_WANDB_TRACE_ADAPTER](ADAPTER_MODULES/01_WANDB_TRACE_ADAPTER/) | Convert trace logs to W&B Tables for auditor analysis | Principle O (Observability) + I4 (Traceability) | âœ… Pilot Complete |
| [02_CI_SAFETY_GATE](ADAPTER_MODULES/02_CI_SAFETY_GATE/) | GitHub Actions workflow for Constitutional Validator | Principle V (Verification) + I1-I6 (All Invariants) | âœ… Pilot Complete |
| 03_HELM_SAFETY_PROFILE | HELM wrapper for TruthfulQA evaluation | Principle T (Truth) | ğŸ”² Not Started |
| 04_SAFETY_CASE_GENERATOR | Generate GSN safety cases from evidence | End-to-End Integration | ğŸ”² Not Started |

### Adapter 01: W&B Trace Adapter (Pilot Complete)

**Evidence Summary**: In a pilot study with 9 synthetic test cases covering F1 (overconfidence), F2 (phantom work), and F4 (incomplete trace) failure modes:

- **52% reduction** in root cause attribution time vs. standard W&B tables
- **100% accuracy** vs. 89% baseline accuracy
- **Statistical significance**: p < 0.0001, Cohen's d = 3.31 (large effect)

See [USE_CASE_EVIDENCE.md](ADAPTER_MODULES/01_WANDB_TRACE_ADAPTER/USE_CASE_EVIDENCE.md) for full validation report.

### Adapter 02: CI Safety Gate (Pilot Complete)

**Evidence Summary**: In a pilot study with 8 seeded test cases covering all 6 constitutional invariants (I1-I6):

- **100% detection rate** on seeded violations (8/8 expected violations detected)
- **0% false positive rate** on clean control case
- **19 total violations** detected across 7 test files
- All invariants validated: I1 (Evidence-First), I2 (No Phantom Work), I3 (Confidence-Verification), I4 (Traceability), I5 (Safety Over Fluency), I6 (Fail Closed)

See [USE_CASE_EVIDENCE.md](ADAPTER_MODULES/02_CI_SAFETY_GATE/USE_CASE_EVIDENCE.md) for full validation report.

---

## Contributing

This is an active research project. Document creation follows the priority order specified above.

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2026-01-18 | Initial repository structure with 6 foundation documents |

---

## License

Research use. Contact author for commercial applications.

---

## Author

Corey Alejandro  
PROACTIVE AI Constitution Framework  
Anthropic Safety AI Research
